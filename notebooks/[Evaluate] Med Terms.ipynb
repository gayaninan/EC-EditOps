{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8Dh2QLRuCZeo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sM4TwQ93ZiIc"
   },
   "outputs": [],
   "source": [
    "def load_medical_dict(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        medical_dict = json.load(file)\n",
    "    medical_terms = set(term for terms in medical_dict.values() for term in terms)\n",
    "    return medical_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "F8gIlF4wF3df"
   },
   "outputs": [],
   "source": [
    "def load_medical_dict(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        medical_dict = json.load(file)\n",
    "    medical_terms = set(term for terms in medical_dict.values() for term in terms)\n",
    "    return medical_terms\n",
    "\n",
    "def preprocess(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "\n",
    "def find_incorrect_terms(trans, refs, medical_terms):\n",
    "    trans_terms = set(preprocess(trans).split())\n",
    "    refs_terms = set(preprocess(refs).split())\n",
    "    return {term for term in refs_terms.intersection(medical_terms) if term not in trans_terms}\n",
    "\n",
    "def check_corrections(incorrect_terms, model_corrected):\n",
    "    corrected_terms = set(preprocess(model_corrected).split())\n",
    "    return incorrect_terms.intersection(corrected_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_med_stats(data_path, all_medical_terms):\n",
    "\n",
    "    data = load_dataset(data_path)\n",
    "    df = data['test'].to_pandas()\n",
    "\n",
    "    df['med_count_refs'] = df['refs'].apply(lambda x: count_medical_terms(x, all_medical_terms))\n",
    "    df['med_count_trans'] = df['trans'].apply(lambda x: count_medical_terms(x, all_medical_terms))\n",
    "\n",
    "    total_medical_terms_count_refs = df['med_count_refs'].sum()\n",
    "    total_medical_terms_count_trans = df['med_count_trans'].sum()\n",
    "\n",
    "    print(f\"Total count of all medical terms in refs: {total_medical_terms_count_refs}\")\n",
    "    print(f\"Total count of all medical terms in trans: {total_medical_terms_count_trans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_medical_terms(text, medical_terms):\n",
    "    text = preprocess_text(text)  \n",
    "    return sum(text.count(term) for term in medical_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    return text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Lj8fFOpoZnm9"
   },
   "outputs": [],
   "source": [
    "def eval_med_terms(med_dict, model_outs, output_path):\n",
    "\n",
    "  medical_terms = load_medical_dict(med_dict)\n",
    "\n",
    "  # all_medical_terms = [term for terms in medical_terms.values() for term in terms]\n",
    "\n",
    "  df = pd.read_csv(model_outs)\n",
    "\n",
    "  df = df.dropna()\n",
    "\n",
    "  total_incorrect = 0\n",
    "  total_corrected = 0\n",
    "\n",
    "  incorrect_lists = []\n",
    "  corrected_lists = []\n",
    "\n",
    "\n",
    "  for _, row in df.iterrows():\n",
    "      incorrect_terms = find_incorrect_terms(row['trans'], row['refs'], medical_terms)\n",
    "      corrected_terms = check_corrections(incorrect_terms, row['model_corrected'])\n",
    "\n",
    "      total_incorrect += len(incorrect_terms)\n",
    "      total_corrected += len(corrected_terms)\n",
    "\n",
    "      incorrect_lists.append(incorrect_terms)\n",
    "      corrected_lists.append(corrected_terms)\n",
    "\n",
    "      if total_incorrect > 0:\n",
    "          improvement_percentage = (total_corrected / total_incorrect) * 100\n",
    "      else:\n",
    "          improvement_percentage = 0\n",
    "\n",
    "  df['med_count_refs'] = df['refs'].apply(lambda x: count_medical_terms(x, medical_terms))\n",
    "  df['med_count_trans'] = df['trans'].apply(lambda x: count_medical_terms(x, medical_terms))\n",
    "\n",
    "  total_medical_terms_count_refs = df['med_count_refs'].sum()\n",
    "  total_medical_terms_count_trans = df['med_count_trans'].sum()\n",
    "\n",
    "    # print(f\"Total count of all medical terms in refs: {total_medical_terms_count_refs}\")\n",
    "    # print(f\"Total count of all medical terms in trans: {total_medical_terms_count_trans}\")\n",
    "    \n",
    "  with open(output_path, 'w') as text_file:\n",
    "        text_file.write(output_path)\n",
    "        text_file.write('Total count of all medical terms in refs : {}\\n' .format(total_medical_terms_count_refs))\n",
    "        text_file.write('Total count of all medical terms in trans: {}\\n'.format(total_medical_terms_count_trans))\n",
    "        text_file.write('Total incorrect/missing medical terms: {}\\n'.format(total_incorrect))\n",
    "        text_file.write('Total corrected terms in model_corrected : {}\\n' .format(total_corrected))\n",
    "        text_file.write('Improvement Percentage: {}\\n'.format(improvement_percentage))\n",
    "\n",
    "  # print(f\"Total incorrect/missing medical terms: {total_incorrect}\")\n",
    "  # # print(incorrect_lists)\n",
    "  # print(f\"Total corrected terms in 'model_corrected': {total_corrected}\")\n",
    "  # # print(corrected_lists)\n",
    "  # print(f\"Improvement Percentage: {improvement_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "_lacu_5_cVcH"
   },
   "outputs": [],
   "source": [
    "eval_med_terms('medical_terms.json', 'n-shot/gpt3-5/gcd/zero_gcd.csv', 'n-shot/gpt3-5/gcd/zero_gcd_med.txt')\n",
    "eval_med_terms('medical_terms.json', 'n-shot/gpt3-5/gcd/one_gcd.csv', 'n-shot/gpt3-5/gcd/one_gcd_med.txt')\n",
    "eval_med_terms('medical_terms.json', 'n-shot/gpt3-5/gcd/two_gcd.csv', 'n-shot/gpt3-5/gcd/two_gcd_med.txt')\n",
    "eval_med_terms('medical_terms.json', 'n-shot/gpt3-5/gcd/few_gcd.csv', 'n-shot/gpt3-5/gcd/few_gcd_med.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNAXBAaKe3Kx",
    "outputId": "e2ab3db5-4740-45cf-8e2e-20e9f607644e"
   },
   "outputs": [],
   "source": [
    "eval_med_terms('medical_terms.json', 'n-shot/gpt3-5/babylon/zero_babylon.csv', 'n-shot/gpt3-5/babylon/zero_babylon_med.txt')\n",
    "eval_med_terms('medical_terms.json', 'n-shot/gpt3-5/babylon/one_babylon.csv', 'n-shot/gpt3-5/babylon/one_babylon_med.txt')\n",
    "eval_med_terms('medical_terms.json', 'n-shot/gpt3-5/babylon/two_babylon.csv', 'n-shot/gpt3-5/babylon/two_babylon_med.txt')\n",
    "eval_med_terms('medical_terms.json', 'n-shot/gpt3-5/babylon/few_babylon.csv', 'n-shot/gpt3-5/babylon/few_babylon_med.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfBGV5G2fBtP",
    "outputId": "8e0b9f7a-64ac-4808-ccad-ad5562e3c195"
   },
   "outputs": [],
   "source": [
    "eval_med_terms('medical_terms.json', 'n-shot/gpt3-5/kaggle/zero_kaggle.csv', 'n-shot/gpt3-5/kaggle/zero_kaggle_med.txt')\n",
    "eval_med_terms('medical_terms.json', 'n-shot/gpt3-5/kaggle/one_kaggle.csv', 'n-shot/gpt3-5/kaggle/one_kaggle_med.txt')\n",
    "eval_med_terms('medical_terms.json', 'n-shot/gpt3-5/kaggle/two_kaggle.csv', 'n-shot/gpt3-5/kaggle/two_kaggle_med.txt')\n",
    "eval_med_terms('medical_terms.json', 'n-shot/gpt3-5/kaggle/few_kaggle.csv', 'n-shot/gpt3-5/kaggle/few_kaggle_med.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
